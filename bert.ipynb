{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"bert-base-uncased\"  # Choose a pre-trained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "text = \"This is an example sentence.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\") \n",
    "outputs = model(**inputs)\n",
    "embeddings = outputs.last_hidden_state  # Access the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BERT models from Google to embed the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datafiles = chunks\n",
    "datafiles = \"chunks/chunk_1.parquet\"\n",
    "dataset = load_dataset(\"parquet\", data_files=datafiles,split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_id', 'rating', 'helpful_vote', 'timestamp', 'asin', 'text', 'title', 'parent_asin', 'verified_purchase', 'embedding'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"bert-base-uncased\"  # Choose a pre-trained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "extractor = pipeline(\n",
    "    'feature-extraction', # We're just interested in the embeddings\n",
    "    model=model_name, # Use BERT\n",
    "    device=0, # Use the GPU\n",
    ")\n",
    "\n",
    "def embed(datum):\n",
    "    # Texts is a list of texts. This is called batching, and it's more\n",
    "    # efficient than running two separate embedding calls.\n",
    "    embeddings = extractor(datum['text'],padding=\"longest\", truncation=True)\n",
    "\n",
    "    # Since we are using a BERT model, we can just use the first embedding, which is\n",
    "    # for the special token CLS. CLS is known ad the \"phrase embedding\"\n",
    "    return { 'embedding': embeddings[0][0] }\n",
    "\n",
    "# Fastest feature extraction possible, using Huggingface datasets.\n",
    "def batch_embed(datum):\n",
    "    \n",
    "    features = extractor(datum['text'], padding=\"longest\", truncation=True)\n",
    "    batch_size = len(datum['text'])\n",
    "    if batch_size > 1:\n",
    "        # We're in batch mode, so massage the data differently\n",
    "        batched_features = []\n",
    "        for b in range(batch_size):\n",
    "            # Since we are using a BERT model, we can just use the first embedding, which is\n",
    "            # for the special token CLS. CLS is known ad the \"phrase embedding\"\n",
    "            batched_features.append(features[b][0][0])\n",
    "        return {'embedding': batched_features }\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example['text'], padding=\"max_length\", truncation=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you embed one piece of text at a time.\n",
    "embed(\"I hate this product with a passion! It sucks balls! I would never ever buy it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you would batch the embedding of the title and the review simultaneously\n",
    "fastembed([\"Don't buy this!\", \"I hate this product with a passion! It sucks balls! I would never ever buy it\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a0f1c036f6479fb7c3b66520161191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "batch_size = 1\n",
    "if batch_size > 1:\n",
    "    dataset = dataset.map(batch_embed, batched=True, batch_size=batch_size)\n",
    "else:\n",
    "    dataset = dataset.map(embed, batched=False)\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_dataset['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the review text\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "dfs['embedding_review'] = dfs['text'].apply(embed)\n",
    "dfs['embedding_title'] = dfs['title'].apply(embed)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Total size of data\n",
    "N = len(dfs)\n",
    "\n",
    "X = [[1]+ fvs[0] + fvs[1] for fvs in zip(dfs['embedding_review'],dfs['embedding_title'])]\n",
    "y = dfs['rating']\n",
    "\n",
    "Ntrain,Nvalid,Ntest = int(N*0.8), int(N*0.1), int(N*0.1)\n",
    "X_train,X_valid,X_test = X[:Ntrain],X[Ntrain:Ntrain+Nvalid],X[Ntrain+Nvalid:]\n",
    "y_train,y_valid,y_test = y[:Ntrain],y[Ntrain:Ntrain+Nvalid],y[Ntrain+Nvalid:]\n",
    "\n",
    "model_lr = sklearn.linear_model.Ridge(1, fit_intercept=False)\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_lr.predict(X_valid)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
